#version 450
#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_GOOGLE_include_directive : require

layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;

#include "include/svoBuilderDescriptorSetLayouts.glsl"

void main() {
  if (gl_GlobalInvocationID.x >= buildInfoBuffer.data.allocNum) return;

  uint idx = gl_GlobalInvocationID.x + buildInfoBuffer.data.allocBegin;

  // if being tagged
  if ((octreeBuffer.uOctree[idx] & 0x80000000u) > 0u) {
    uvec4 ballot = subgroupBallot(true);
    // the goal here is to reduce the computational stress bringing to GPU
    // syncronization by eliminating the calls of atomicAdd (only 1 / 32 for
    // Nvidia cards)

    // the optimization is viable because of the bit flagging of ballot
    uint cur_base;
    if (subgroupElect()) {
      // it returns the value BEFORE the addition
      // after this step, cur_base stores the original active pointer within
      // that buffer to write to, and the active pointer is incremented by the
      // number of active threads within the subgroup
      cur_base = atomicAdd(counterBuffer.uCounter, subgroupBallotBitCount(ballot));
    }
    // sync that active pointer val to all threads within the subgroup
    cur_base = subgroupBroadcastFirst(cur_base);

    // get the position to write without any collision
    uint cur = cur_base + subgroupBallotExclusiveBitCount(ballot);

    // << 3u is equivalent to * 8u, which is the size of each node
    octreeBuffer.uOctree[idx] = (cur << 3u) | 0x80000000u;
  }
}

// void main() {
//   if (gl_GlobalInvocationID.x >= buildInfoBuffer.data.allocNum) return;

//   uint idx = gl_GlobalInvocationID.x + buildInfoBuffer.data.allocBegin;

//   // if being tagged
//   if ((uOctree[idx] & 0x80000000u) > 0u) {
//     uOctree[idx] = ((atomicAdd(uCounter, 1u)) << 3u) | 0x80000000u;
//   }
// }
