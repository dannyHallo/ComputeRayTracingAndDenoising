#version 450
#extension GL_GOOGLE_include_directive : require

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

#include "../include/svoTracerDescriptorSetLayouts.glsl"

#include "../include/cascadedMarching.glsl"
#include "../include/core/definitions.glsl"
#include "../include/core/packer.glsl"
#include "../include/projection.glsl"
#include "../include/random.glsl"
#include "../include/skyColor.glsl"

// subpixOffset ranges from -0.5 to 0.5
void rayGen(out vec3 o, out vec3 d, vec2 subpixOffset) {
  vec2 screenSpaceUv = (vec2(gl_GlobalInvocationID.xy) + vec2(0.5) + subpixOffset) /
                       vec2(renderInfoUbo.data.lowResSize);
  o = renderInfoUbo.data.camPosition;
  d = normalize(projectScreenUvToWorldCamFarPoint(screenSpaceUv, false) -
                renderInfoUbo.data.camPosition);
}

uvec3 getSeed() {
  return uvec3(gl_GlobalInvocationID.x, gl_GlobalInvocationID.y, renderInfoUbo.data.currentSample);
}

vec3 getShadowRayColor(vec3 o, vec3 d) {
  MarchingResult shadowRayResult;
  bool shadowRayHit = cascadedMarching(shadowRayResult, o, d);
  if (shadowRayHit) {
    return vec3(0.0);
  }
  return 1000 * skyColor(d, true);
}

vec3 getIndirectRayColor(vec3 o, vec3 d, uvec3 seed, vec3 shadowRayDirReuse) {
  MarchingResult indirectRayResult;

  bool indirectRayHit = cascadedMarching(indirectRayResult, o, d);
  if (!indirectRayHit) {
    // exclude the sun light here!
    return skyColor(d, false);
  }

  // reuse the shadow ray dir for better performance
  vec3 shadowRay2Color = vec3(0.0);
  if (dot(shadowRayDirReuse, indirectRayResult.normal) >= 0.0) {
    shadowRay2Color = getShadowRayColor(indirectRayResult.nextTracingPosition, shadowRayDirReuse);
    vec3 brdf       = indirectRayResult.color * kInvPi;
    const float shadowRayPdf = 1.0 / (0.0001 * kPi);
    shadowRay2Color *= brdf * dot(shadowRayDirReuse, indirectRayResult.normal) / shadowRayPdf;
  }

  return shadowRay2Color;
}

// most of the return value is only valid if hit, except for oPrimaryRayIterUsed
bool getPrimaryRayColor(out float oT, out uint oPrimaryRayIterUsed,
                        out uint oPrimaryRayChunkTraversed, out vec3 oColor, out vec3 oPosition,
                        out vec3 oNormal, out uint oVoxHash, uvec3 seed, vec3 o, vec3 d,
                        float optimizedDistance) {
  o += d * optimizedDistance;

  MarchingResult primaryRayResult;
  bool primaryRayHit = cascadedMarching(primaryRayResult, o, d);

  oT                        = primaryRayResult.t;
  oPrimaryRayIterUsed       = primaryRayResult.iter;
  oPrimaryRayChunkTraversed = primaryRayResult.chunkTraversed;
  oColor                    = primaryRayResult.color;
  oPosition                 = primaryRayResult.position;
  oNormal                   = primaryRayResult.normal;
  oVoxHash                  = primaryRayResult.voxHash;

  oT += optimizedDistance;

  if (!primaryRayHit) {
    oT        = 1e10;
    oPosition = o + d * oT;
    oColor    = skyColor(d, true);
    return false;
  }

  // TODO: debug feature: show normal
  // return true;

  vec3 brdf = primaryRayResult.color * kInvPi;

  // direct contribution
  vec3 shadowRayDir   = getRandomShadowRay(makeDisturbedSeed(seed, 1));
  vec3 shadowRayColor = vec3(0.0);
  if (dot(shadowRayDir, primaryRayResult.normal) >= 0.0) {
    shadowRayColor = getShadowRayColor(primaryRayResult.nextTracingPosition, shadowRayDir);
    const float shadowRayPdf = 1.0 / (0.0001 * kPi);
    shadowRayColor *= brdf * dot(shadowRayDir, primaryRayResult.normal) / shadowRayPdf;
  }

  if (tweakableParametersUbo.data.traceIndirectRay == 0u) {
    oColor = shadowRayColor;
    return true;
  }

  // indirect contribution
  vec3 indirectRayDir =
      randomCosineWeightedHemispherePoint(primaryRayResult.normal, makeDisturbedSeed(seed, 2));
  vec3 indirectRayColor =
      getIndirectRayColor(primaryRayResult.nextTracingPosition, indirectRayDir, seed, shadowRayDir);

  float indirectRayPdf = dot(indirectRayDir, primaryRayResult.normal) / kPi;
  indirectRayColor *= brdf * dot(indirectRayDir, primaryRayResult.normal) / indirectRayPdf;

  oColor = shadowRayColor + indirectRayColor;
  return true;
}

void writeOutputBuffer(ivec2 uvi, bool hitVoxel, vec3 position) {
  // if uvi is not the center pixel, we don't write the output buffer
  if (uvi != ivec2(renderInfoUbo.data.lowResSize) / 2) {
    return;
  }
  outputInfoBuffer.data.midRayHit    = uint(hitVoxel);
  outputInfoBuffer.data.midRayHitPos = position;
}

void main() {
  ivec2 uvi = ivec2(gl_GlobalInvocationID.xy);
  if (any(greaterThanEqual(uvi, ivec2(renderInfoUbo.data.lowResSize)))) {
    return;
  }

  uvec3 seed = getSeed();

  vec3 o, d;
  // (-0.5, 0.5)
  vec2 subpixOffset =
      bool(tweakableParametersUbo.data.taa) ? renderInfoUbo.data.subpixOffset : vec2(0);
  rayGen(o, d, subpixOffset);

  float optimizedDistance = 0;

  // beam optimization
  if (bool(tweakableParametersUbo.data.beamOptimization)) {
    ivec2 beamUv      = ivec2(gl_GlobalInvocationID.xy / sceneInfoBuffer.data.beamResolution);
    float t1          = imageLoad(beamDepthImage, beamUv).r;
    float t2          = imageLoad(beamDepthImage, beamUv + ivec2(1, 0)).r;
    float t3          = imageLoad(beamDepthImage, beamUv + ivec2(0, 1)).r;
    float t4          = imageLoad(beamDepthImage, beamUv + ivec2(1, 1)).r;
    float t           = min(min(t1, t2), min(t3, t4));
    optimizedDistance = t;
  }

  uint voxHash;
  uint primaryRayIterUsed;
  uint primaryRayChunkTraversed;
  vec3 normal, position, color;
  float tMin;
  bool hitVoxel = getPrimaryRayColor(tMin, primaryRayIterUsed, primaryRayChunkTraversed, color,
                                     position, normal, voxHash, seed, o, d, optimizedDistance);

  if (hitVoxel) {
    imageStore(positionImage, uvi, vec4(position, 0.0));
    imageStore(normalImage, uvi, uvec4(packNormal(normal), 0, 0, 0));
    imageStore(voxHashImage, uvi, uvec4(voxHash, 0, 0, 0));
  }
  imageStore(depthImage, uvi, vec4(tMin, 0.0, 0.0, 0.0));

  // calculate the motion here avoids a store - load cycle for the position, and the motion vector
  // can be reused in temporal filter and the taa filter, also, using a motion vector is easier for
  // us to handle moving objects in the future
  vec2 pUv01 = projectWorldPosToScreenUv(position, true);
  vec2 uv01  = projectWorldPosToScreenUv(position, false);
  // the motion vector points to the previous frame, and is normalized
  vec2 motion = pUv01 - uv01;

  imageStore(hitImage, uvi, uvec4(hitVoxel ? 1 : 0, 0, 0, 0));
  imageStore(motionImage, uvi, vec4(motion, 0, 0));

  uint packedColor = packRgbe(color);
  if (hitVoxel) {
    imageStore(rawImage, uvi, uvec4(packedColor, 0, 0, 0));
  } else {
    imageStore(backgroundImage, uvi, uvec4(packedColor, 0, 0, 0));
  }

  const vec3 iterUsedColor       = vec3(1, 0.4, 0.2) * 0.02 * float(primaryRayIterUsed);
  const vec3 chunkTraversedColor = vec3(0.2, 0.4, 1) * 0.2 * float(primaryRayChunkTraversed);

  vec3 overlappingColor = vec3(0);
  if (bool(tweakableParametersUbo.data.visualizeOctree)) {
    overlappingColor += iterUsedColor;
  }
  if (bool(tweakableParametersUbo.data.visualizeChunks)) {
    overlappingColor += chunkTraversedColor;
  }

  imageStore(octreeVisualizationImage, uvi, vec4(overlappingColor, 0));

  writeOutputBuffer(uvi, hitVoxel, position);
}
